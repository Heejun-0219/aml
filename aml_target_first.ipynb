{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\", input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "        model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_targeted_adversary(model, image, target, eps=2 / 255.0):\n",
    "    # Create a target label that is the opposite of the true label\n",
    "    target_label = to_categorical([target], num_classes=10)\n",
    "\n",
    "    # Cast the image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    # Record our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image)\n",
    "        pred = model(image)\n",
    "        loss = CategoricalCrossentropy()(target_label, pred)\n",
    "\n",
    "    # Calculate the gradients of loss with respect to the image, then compute the sign of the gradient\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    signedGrad = tf.sign(gradient)\n",
    "\n",
    "    # Construct the image adversary by subtracting the signed gradient\n",
    "    adversary = (image - (signedGrad * eps)).numpy()\n",
    "    return adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset and scale the pixel values to the range [0, 1]\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "\n",
    "# add a channel dimension to the images\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "# one-hot encode our labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "# initialize our optimizer and model\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the simple CNN on MNIST\n",
    "model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an image adversary for the current image and make a prediction on the adversary\n",
    "for i in np.random.choice(np.arange(0, len(testX)), size=(10,)):\n",
    "    image = testX[i]\n",
    "    true_label = np.argmax(testY[i])\n",
    "    target_label = (true_label + 1) % 10  # Choose a target class different from true class\n",
    "    adversary = generate_targeted_adversary(model, image.reshape(1, 28, 28, 1), target_label, eps=0.1)\n",
    "    pred = model.predict(adversary)\n",
    "\n",
    "    # Visualize and compare the original and adversarial images\n",
    "    adversary = adversary.reshape((28, 28)) * 255\n",
    "    adversary = np.clip(adversary, 0, 255).astype(\"uint8\")\n",
    "    image = image.reshape((28, 28)) * 255\n",
    "    image = image.astype(\"uint8\")\n",
    "\n",
    "    image = np.dstack([image] * 3)\n",
    "    adversary = np.dstack([adversary] * 3)\n",
    "    image = cv2.resize(image, (96, 96))\n",
    "    adversary = cv2.resize(adversary, (96, 96))\n",
    "\n",
    "    imagePred = np.argmax(testY[i])\n",
    "    adversaryPred = pred[0].argmax()\n",
    "    color = (0, 255, 0) if imagePred == adversaryPred else (0, 0, 255)\n",
    "\n",
    "    cv2.putText(image, str(imagePred), (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.95, (0, 255, 0), 2)\n",
    "    cv2.putText(adversary, str(adversaryPred), (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.95, color, 2)\n",
    "\n",
    "    output = np.hstack([image, adversary])\n",
    "    cv2_imshow(output)\n",
    "    cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
